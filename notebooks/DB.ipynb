{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b3ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a88ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMySQLCursor: (Nothing executed yet)\n"
     ]
    }
   ],
   "source": [
    "mydb = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"Mysql.2022\")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "print(mycursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d5db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mycursor.execute(\"CREATE DATABASE MEDfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968d50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"USE  MEDfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd3528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e66a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Networks table\n",
    "mycursor.execute(\n",
    "    \"CREATE TABLE Networks( \\\n",
    "                 NetId INT NOT NULL AUTO_INCREMENT, \\\n",
    "                 NetName VARCHAR(255), \\\n",
    "                 PRIMARY KEY (NetId) \\\n",
    "                 );\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f27b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nodes table\n",
    "mycursor.execute(\n",
    "    \"CREATE TABLE Nodes( \\\n",
    "                 NodeId INT NOT NULL AUTO_INCREMENT, \\\n",
    "                 NodeName VARCHAR(255), \\\n",
    "                 Online BOOL DEFAULT 1,\\\n",
    "                 NetId INT,\\\n",
    "                 PRIMARY KEY (NodeId), \\\n",
    "                 FOREIGN KEY (NetId) REFERENCES Networks(NetId)\\\n",
    "                 )\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b90fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e048b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12893 entries, 0 to 12892\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             12893 non-null  object \n",
      " 1   site_hospital  12893 non-null  object \n",
      " 2   site_region    11937 non-null  object \n",
      " 3   age            12893 non-null  int64  \n",
      " 4   pao2fio2       9472 non-null   float64\n",
      " 5   uo             12893 non-null  int64  \n",
      " 6   admissiontype  12893 non-null  float64\n",
      " 7   bicarbonate    12893 non-null  int64  \n",
      " 8   bilirubin      12893 non-null  int64  \n",
      " 9   bun            12893 non-null  int64  \n",
      " 10  chron_dis      12893 non-null  int64  \n",
      " 11  gcs            12893 non-null  int64  \n",
      " 12  hr             12893 non-null  int64  \n",
      " 13  potassium      12893 non-null  int64  \n",
      " 14  sbp            12893 non-null  int64  \n",
      " 15  sodium         12893 non-null  int64  \n",
      " 16  tempc          12893 non-null  int64  \n",
      " 17  wbc            12893 non-null  int64  \n",
      " 18  event_death    12893 non-null  int64  \n",
      "dtypes: float64(2), int64(14), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv(\n",
    "    \"~/Desktop/Github/MEDfl/Medfl/Notebooks/sapsii_score_knnimputed_eicu.csv\"\n",
    ")\n",
    "\n",
    "columns = data_df.columns.tolist()\n",
    "\n",
    "\n",
    "column_map = {\"object\": \"VARCHAR(255)\", \"int64\": \"INT\", \"float64\": \"FLOAT\"}\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e0adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id VARCHAR(255),site_hospital VARCHAR(255),site_region VARCHAR(255),age INT,pao2fio2 FLOAT,uo INT,admissiontype FLOAT,bicarbonate INT,bilirubin INT,bun INT,chron_dis INT,gcs INT,hr INT,potassium INT,sbp INT,sodium INT,tempc INT,wbc INT,event_death INT,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_query = \"\".join(f\"{col} {column_map[str(data_df[col].dtype)]},\" for col in columns)\n",
    "sub_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926d1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset table\n",
    "mycursor.execute(\n",
    "    f\"CREATE TABLE DataSets( \\\n",
    "                 DataSetId INT NOT NULL AUTO_INCREMENT, \\\n",
    "                 DataSetName VARCHAR(255), \\\n",
    "                 NodeId INT,\\\n",
    "                 {sub_query}\\\n",
    "                 PRIMARY KEY (DataSetId), \\\n",
    "                 FOREIGN KEY (NodeId) REFERENCES Nodes(NodeId)\\\n",
    "                 )\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6270b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e2157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "my_eng = create_engine(\"mysql+mysqlconnector://root:Mysql.2022@localhost:3306/MEDfl\")\n",
    "my_eng = my_eng.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ddd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def create_network(self):\n",
    "        mycursor.execute(f\"INSERT INTO Networks( NetName) VALUES ('{self.name}')\")\n",
    "        mydb.commit()\n",
    "\n",
    "    def delete_network(self):\n",
    "        mycursor.execute(f\"DELETE FROM Networks WHERE NetName = '{self.name}'\")\n",
    "        mydb.commit()\n",
    "\n",
    "    def update_network(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def list_allnetworks():\n",
    "        mycursor.execute(\"SELECT * FROM Networks\")\n",
    "        myresult = mycursor.fetchall()\n",
    "        return myresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30eeeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = Network(\"Net1\")\n",
    "# Net.create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f795b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Net1')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Net.list_allnetworks()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5748cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def create_node(self, NetId: int, Online: int):\n",
    "        mycursor.execute(\n",
    "            f\"INSERT INTO Nodes(NodeName,NetId,Online) VALUES ('{self.name}',{NetId}, {Online})\"\n",
    "        )\n",
    "        mydb.commit()\n",
    "\n",
    "    def delete_node(self):\n",
    "        mycursor.execute(f\"DELETE FROM Nodes WHERE NodeName = '{self.name}'\")\n",
    "        mydb.commit()\n",
    "\n",
    "    def update_node(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def list_allnodes():\n",
    "        query = text(\"SELECT * FROM Nodes\")\n",
    "        res = pd.read_sql(query, my_eng)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb7c89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.reset_index()  # make sure indexes pair with number of rows\n",
    "path = \"~/Desktop/Github/MEDfl/Medfl/Notebooks/sapsii_score_knnimputed_eicu.csv\"\n",
    "\n",
    "\n",
    "def is_str(data_df, row, x):\n",
    "    if data_df[x].dtype == \"object\":\n",
    "        x = f\"'{row[x]}'\"\n",
    "    else:\n",
    "        x = row[x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd2bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6290d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, name: str, path: str):\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "\n",
    "    def upload_dataset(self, NodeId):\n",
    "        data_df = pd.read_csv(self.path)\n",
    "        columns = data_df.columns.tolist()\n",
    "\n",
    "        column_map = {\"object\": \"VARCHAR(255)\", \"int64\": \"INT\", \"float64\": \"FLOAT\"}\n",
    "        data_df[\"pao2fio2\"].fillna(data_df[\"pao2fio2\"].mean(), inplace=True)\n",
    "        print(data_df[\"site_region\"].unique())\n",
    "        data_df[\"site_region\"].fillna(data_df[\"site_region\"].mode()[0], inplace=True)\n",
    "        print(data_df[\"site_region\"].unique())\n",
    "        try:\n",
    "            data_df = data_df.reset_index()\n",
    "        except:\n",
    "            pass\n",
    "        print(data_df.columns.to_list())\n",
    "        # data_df = data_df.head(1)\n",
    "        for index, row in data_df.iterrows():\n",
    "            query_1 = \"INSERT INTO DataSets(DataSetName,NodeId,\" + \"\".join(\n",
    "                f\"{x},\" for x in columns\n",
    "            )\n",
    "            query_2 = f\" VALUES ('{self.name}',{DomainId}, \" + \"\".join(\n",
    "                f\"{is_str(data_df,row,x)},\" for x in columns\n",
    "            )\n",
    "\n",
    "            query = query_1[:-1] + \")\" + query_2[:-1] + \")\"\n",
    "            mycursor.execute(query)\n",
    "        mydb.commit()\n",
    "\n",
    "    def delete_dataset(self):\n",
    "        mycursor.execute(f\"DELETE  FROM DataSets WHERE DatasetName = '{self.name}'\")\n",
    "        mydb.commit()\n",
    "\n",
    "    def update_data(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def list_alldatasets():\n",
    "        query = text(\"SELECT DISTINCT DataSetName  FROM DataSets\")\n",
    "        res = pd.read_sql(query, my_eng)\n",
    "        return res\n",
    "\n",
    "    def get_dataset(self):\n",
    "        query = text(f\"SELECT * FROM  DataSets WHERE DataSetName = '{self.name}'  \")\n",
    "        res = pd.read_sql(query, my_eng)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a9686c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet(\"Dataset_1\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cf729dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.delete_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9f98b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Midwest' nan 'South' 'West' 'Northeast']\n",
      "['Midwest' 'South' 'West' 'Northeast']\n",
      "['index', 'id', 'site_hospital', 'site_region', 'age', 'pao2fio2', 'uo', 'admissiontype', 'bicarbonate', 'bilirubin', 'bun', 'chron_dis', 'gcs', 'hr', 'potassium', 'sbp', 'sodium', 'tempc', 'wbc', 'event_death']\n"
     ]
    }
   ],
   "source": [
    "ds.upload_dataset(NodeId=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7a71b4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSetName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DataSetName\n",
       "0   Dataset_1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = ds.list_alldatasets()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "573927e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSetId</th>\n",
       "      <th>DataSetName</th>\n",
       "      <th>DomainId</th>\n",
       "      <th>id</th>\n",
       "      <th>site_hospital</th>\n",
       "      <th>site_region</th>\n",
       "      <th>age</th>\n",
       "      <th>pao2fio2</th>\n",
       "      <th>uo</th>\n",
       "      <th>admissiontype</th>\n",
       "      <th>...</th>\n",
       "      <th>bun</th>\n",
       "      <th>chron_dis</th>\n",
       "      <th>gcs</th>\n",
       "      <th>hr</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sbp</th>\n",
       "      <th>sodium</th>\n",
       "      <th>tempc</th>\n",
       "      <th>wbc</th>\n",
       "      <th>event_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180542</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay147985</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180543</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay156248</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180544</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay156308</td>\n",
       "      <td>site60</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180545</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay157820</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180546</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay159036</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12888</th>\n",
       "      <td>193430</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay3345830</td>\n",
       "      <td>site458</td>\n",
       "      <td>South</td>\n",
       "      <td>12</td>\n",
       "      <td>1.41987</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12889</th>\n",
       "      <td>193431</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay3347760</td>\n",
       "      <td>site459</td>\n",
       "      <td>South</td>\n",
       "      <td>7</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12890</th>\n",
       "      <td>193432</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay3349092</td>\n",
       "      <td>site458</td>\n",
       "      <td>South</td>\n",
       "      <td>7</td>\n",
       "      <td>1.41987</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12891</th>\n",
       "      <td>193433</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay3351413</td>\n",
       "      <td>site458</td>\n",
       "      <td>South</td>\n",
       "      <td>12</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>193434</td>\n",
       "      <td>Dataset_1</td>\n",
       "      <td>1</td>\n",
       "      <td>stay3352961</td>\n",
       "      <td>site459</td>\n",
       "      <td>South</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12893 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DataSetId DataSetName  DomainId           id site_hospital site_region  \\\n",
       "0         180542   Dataset_1         1   stay147985        site73     Midwest   \n",
       "1         180543   Dataset_1         1   stay156248        site73     Midwest   \n",
       "2         180544   Dataset_1         1   stay156308        site60     Midwest   \n",
       "3         180545   Dataset_1         1   stay157820        site73     Midwest   \n",
       "4         180546   Dataset_1         1   stay159036        site73     Midwest   \n",
       "...          ...         ...       ...          ...           ...         ...   \n",
       "12888     193430   Dataset_1         1  stay3345830       site458       South   \n",
       "12889     193431   Dataset_1         1  stay3347760       site459       South   \n",
       "12890     193432   Dataset_1         1  stay3349092       site458       South   \n",
       "12891     193433   Dataset_1         1  stay3351413       site458       South   \n",
       "12892     193434   Dataset_1         1  stay3352961       site459       South   \n",
       "\n",
       "       age  pao2fio2  uo  admissiontype  ...  bun  chron_dis  gcs  hr  \\\n",
       "0       16   0.00000   4            6.0  ...    6          0    5   0   \n",
       "1        7   0.00000   0            6.0  ...    0          0    0   0   \n",
       "2       18   0.00000   0            6.0  ...    6          0    0   0   \n",
       "3       12   0.00000  11            6.0  ...   10          0    0   0   \n",
       "4       18   0.00000   0            6.0  ...    6          0    0   4   \n",
       "...    ...       ...  ..            ...  ...  ...        ...  ...  ..   \n",
       "12888   12   1.41987   0            6.0  ...    0          0    0   2   \n",
       "12889    7   6.00000   0            6.0  ...    6          0    7   2   \n",
       "12890    7   1.41987   0            0.0  ...    6          0    0   2   \n",
       "12891   12  11.00000   0            6.0  ...    0          0    7   2   \n",
       "12892   15   0.00000   0            6.0  ...    0          0   13   2   \n",
       "\n",
       "       potassium  sbp  sodium  tempc  wbc  event_death  \n",
       "0              0    5       1      0    0            1  \n",
       "1              0    5       0      0    0            0  \n",
       "2              3    5       1      0    0            0  \n",
       "3              0    0       1      0    0            0  \n",
       "4              0    5       0      0    3            0  \n",
       "...          ...  ...     ...    ...  ...          ...  \n",
       "12888          0    5       0      0    0            0  \n",
       "12889          3    5       5      0    3            0  \n",
       "12890          0    0       0      0    0            0  \n",
       "12891          0   13       0      0    0            0  \n",
       "12892          0    0       0      3    0            0  \n",
       "\n",
       "[12893 rows x 22 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ds.get_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d787eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = ds.create_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ded03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_dataset(node_name):\n",
    "    return pd.read_sql(\n",
    "        text(f\"SELECT * FROM DataSets WHERE NodeName = '{node_name}'\"), my_eng\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "115535c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, test_data):\n",
    "    testdata = None\n",
    "    encoder = LabelEncoder()\n",
    "    data[\"site_hospital\"] = encoder.fit_transform(data[\"site_hospital\"].astype(str))\n",
    "    data[\"site_region\"] = encoder.fit_transform(data[\"site_region\"].astype(str))\n",
    "    X, y = (\n",
    "        data.drop([\"DataSetId\", \"DataSetName\", \"id\", \"event_death\"], axis=1),\n",
    "        data[\"event_death\"],\n",
    "    )\n",
    "    X, y = torch.tensor(X.values, dtype=torch.float32), torch.tensor(\n",
    "        y.values, dtype=torch.float32\n",
    "    )\n",
    "    data = TensorDataset(X_train, y_train)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d3ff861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(train_nodes: list, test_nodes: list, val_frac=0.1, test_frac=0.2):\n",
    "    trainloaders, valloaders, testloader = [], [], None\n",
    "    num_client = len(train_nodes)\n",
    "    if test_nodes is None:\n",
    "        dataset = get_node_dataset(train_nodes[0])\n",
    "        dataset_size = dataset.shape[0]\n",
    "        _, testdata = torch.utils.data.random_split(\n",
    "            dataset, [dataset_size * (1 - test_frac), dataset_size * test_frac]\n",
    "        )\n",
    "        testloader = DataLoader(test_data, batch_size=1)\n",
    "    else:\n",
    "        testdatas = []\n",
    "        for train_node in train_nodes:\n",
    "            dataset = get_node_dataset(train_node)\n",
    "            dataset = process_data(dataset)\n",
    "            dataset_size = dataset.shape[0]\n",
    "            traindata, valdata = torch.utils.data.random_split(\n",
    "                dataset, [dataset_size * (1 - val_frac), dataset_size * val_frac]\n",
    "            )\n",
    "            trainloaders.append(DataLoader(traindata, batch_size=32, shuffle=True))\n",
    "            valloaders.append(DataLoader(valdata, batch_size=32))\n",
    "\n",
    "        for test_node in test_nodes:\n",
    "            dataset = get_node_dataset(test_node)\n",
    "            testdatas.append(dataset)\n",
    "        # create the  testloader\n",
    "        testdata = [testdatas[0].append(x, ignore_index=True) for x in testdatas[1:]][0]\n",
    "        testdata = process_data(testdata)\n",
    "        testloader = DataLoader(testdata, batch_size=1)\n",
    "    return trainloaders, valloaders, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f97c9",
   "metadata": {},
   "source": [
    "<h2>Scénario</h2>\n",
    "<ol>\n",
    "    <li>Création du réseau eICU</li>\n",
    "    <li> Création des noeuds d'entraînements (UDES,UQAM,UQAR) </li>\n",
    "    <li> Création des noeuds de test (McGill,PMTL) </li>\n",
    "    <li></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes, test_nodes = [\"UDES\", \"UQAM\", \"UQAR\"], [\"McGill\", \"PMTL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f102fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"/home/hlpc/Desktop/Github/MEDfl/\")\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/hlpc/Desktop/Github/MEDfl/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "056aa919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Medfl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4ababc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Medfl.Federated.dataset import *\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "dataset = Dataset(train_data, test_data, num_clients=NUM_CLIENTS)\n",
    "\n",
    "dataset.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5d56c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc1): Linear(in_features=17, out_features=34, bias=True)\n",
       "  (fc2): Linear(in_features=34, out_features=68, bias=True)\n",
       "  (fc3): Linear(in_features=68, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "from Medfl.Federated.model import *\n",
    "\n",
    "global_model = LogisticRegression(\n",
    "    input_dim=dataset.size, hidden_dim=2 * dataset.size, output_dim=1\n",
    ")\n",
    "global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bed22b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a server\n",
    "from Medfl.Federated.server import *\n",
    "\n",
    "server = FlowerServer(\n",
    "    global_model,\n",
    "    strategy=\"FedAvg\",\n",
    "    num_rounds=3,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    dataset=dataset,\n",
    "    diff_privacy=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "71db71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "from Medfl.Federated.pipeline import *\n",
    "\n",
    "ppl_1 = pipeline(pp_id=1, pp_name=\"test_pipeline\", server=server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "68323f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-02 12:29:58,902 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "03/02/2023 12:29:58:INFO:Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-03-02 12:30:03,627\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-03-02 12:30:04,882 | app.py:179 | Flower VCE: Ray initialized with resources: {'node:192.168.43.27': 1.0, 'CPU': 4.0, 'object_store_memory': 2870066380.0, 'memory': 5740132763.0}\n",
      "03/02/2023 12:30:04:INFO:Flower VCE: Ray initialized with resources: {'node:192.168.43.27': 1.0, 'CPU': 4.0, 'object_store_memory': 2870066380.0, 'memory': 5740132763.0}\n",
      "INFO flwr 2023-03-02 12:30:04,887 | server.py:86 | Initializing global parameters\n",
      "03/02/2023 12:30:04:INFO:Initializing global parameters\n",
      "INFO flwr 2023-03-02 12:30:04,894 | server.py:266 | Using initial parameters provided by strategy\n",
      "03/02/2023 12:30:04:INFO:Using initial parameters provided by strategy\n",
      "INFO flwr 2023-03-02 12:30:04,898 | server.py:88 | Evaluating initial parameters\n",
      "03/02/2023 12:30:04:INFO:Evaluating initial parameters\n",
      "INFO flwr 2023-03-02 12:30:04,918 | server.py:91 | initial parameters (loss, other metrics): 0.026872602087506175, {'accuracy': 0.5088757396449705}\n",
      "03/02/2023 12:30:04:INFO:initial parameters (loss, other metrics): 0.026872602087506175, {'accuracy': 0.5088757396449705}\n",
      "INFO flwr 2023-03-02 12:30:04,920 | server.py:101 | FL starting\n",
      "03/02/2023 12:30:04:INFO:FL starting\n",
      "DEBUG flwr 2023-03-02 12:30:04,923 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:04:DEBUG:fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.026872602087506175 / accuracy 0.5088757396449705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m /home/hlpc/anaconda3/envs/openmined/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m epsilon of client 6 : eps = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m /home/hlpc/anaconda3/envs/openmined/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m   warnings.warn(\n",
      "DEBUG flwr 2023-03-02 12:30:08,022 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-02 12:30:08,029 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "03/02/2023 12:30:08:WARNING:No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2023-03-02 12:30:08,039 | server.py:116 | fit progress: (1, 0.026610170948434864, {'accuracy': 0.5562130177514792}, 3.115706107999358)\n",
      "03/02/2023 12:30:08:INFO:fit progress: (1, 0.026610170948434864, {'accuracy': 0.5562130177514792}, 3.115706107999358)\n",
      "DEBUG flwr 2023-03-02 12:30:08,041 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m /home/hlpc/anaconda3/envs/openmined/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m   warnings.warn(\n",
      "DEBUG flwr 2023-03-02 12:30:08,096 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-02 12:30:08,099 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "03/02/2023 12:30:08:WARNING:No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-02 12:30:08,104 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:08:DEBUG:fit_round 2: strategy sampled 3 clients (out of 10)\n",
      "DEBUG flwr 2023-03-02 12:30:08,162 | server.py:229 | fit_round 2 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:fit_round 2 received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m epsilon of client 8 : eps = 0\n",
      "Server-side evaluation loss 0.026610170948434864 / accuracy 0.5562130177514792\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m epsilon of client 0 : eps = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-02 12:30:08,184 | server.py:116 | fit progress: (2, 0.026430375124575824, {'accuracy': 0.5443786982248521}, 3.2604404489993613)\n",
      "03/02/2023 12:30:08:INFO:fit progress: (2, 0.026430375124575824, {'accuracy': 0.5443786982248521}, 3.2604404489993613)\n",
      "DEBUG flwr 2023-03-02 12:30:08,186 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
      "DEBUG flwr 2023-03-02 12:30:08,236 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-02 12:30:08,238 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:08:DEBUG:fit_round 3: strategy sampled 3 clients (out of 10)\n",
      "DEBUG flwr 2023-03-02 12:30:08,288 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:fit_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-03-02 12:30:08,304 | server.py:116 | fit progress: (3, 0.026424193523339266, {'accuracy': 0.5384615384615384}, 3.3809996979998687)\n",
      "03/02/2023 12:30:08:INFO:fit progress: (3, 0.026424193523339266, {'accuracy': 0.5384615384615384}, 3.3809996979998687)\n",
      "DEBUG flwr 2023-03-02 12:30:08,306 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
      "DEBUG flwr 2023-03-02 12:30:08,358 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "03/02/2023 12:30:08:DEBUG:evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-03-02 12:30:08,360 | server.py:144 | FL finished in 3.43705915999999\n",
      "03/02/2023 12:30:08:INFO:FL finished in 3.43705915999999\n",
      "INFO flwr 2023-03-02 12:30:08,361 | app.py:202 | app_fit: losses_distributed [(1, 0.025494377523719445), (2, 0.025631307027278803), (3, 0.025688351493850497)]\n",
      "03/02/2023 12:30:08:INFO:app_fit: losses_distributed [(1, 0.025494377523719445), (2, 0.025631307027278803), (3, 0.025688351493850497)]\n",
      "INFO flwr 2023-03-02 12:30:08,364 | app.py:203 | app_fit: metrics_distributed {}\n",
      "03/02/2023 12:30:08:INFO:app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-03-02 12:30:08,365 | app.py:204 | app_fit: losses_centralized [(0, 0.026872602087506175), (1, 0.026610170948434864), (2, 0.026430375124575824), (3, 0.026424193523339266)]\n",
      "03/02/2023 12:30:08:INFO:app_fit: losses_centralized [(0, 0.026872602087506175), (1, 0.026610170948434864), (2, 0.026430375124575824), (3, 0.026424193523339266)]\n",
      "INFO flwr 2023-03-02 12:30:08,367 | app.py:205 | app_fit: metrics_centralized {'accuracy': [(0, 0.5088757396449705), (1, 0.5562130177514792), (2, 0.5443786982248521), (3, 0.5384615384615384)]}\n",
      "03/02/2023 12:30:08:INFO:app_fit: metrics_centralized {'accuracy': [(0, 0.5088757396449705), (1, 0.5562130177514792), (2, 0.5443786982248521), (3, 0.5384615384615384)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14474)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m epsilon of client 2 : eps = 0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14476)\u001b[0m [Client 6] evaluate, config: {}\n",
      "Server-side evaluation loss 0.026430375124575824 / accuracy 0.5443786982248521\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m epsilon of client 6 : eps = 0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14473)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m epsilon of client 1 : eps = 0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14474)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14474)\u001b[0m epsilon of client 3 : eps = 0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14476)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14476)\u001b[0m epsilon of client 7 : eps = 0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14473)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=14473)\u001b[0m epsilon of client 8 : eps = 0\n",
      "Server-side evaluation loss 0.026424193523339266 / accuracy 0.5384615384615384\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14474)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14476)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=14473)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    }
   ],
   "source": [
    "ppl_1.server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b97dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
