{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated-Transfer learning Tutorial âˆ’ Integrating Transfer learning to Federated Learning using MEDfl package\n",
    "\n",
    "@Author : [MEDomics consortium](https://github.com/medomics/)\n",
    "\n",
    "@Email : medomics.info@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the process of integrating [Transfer learning](https://ieeexplore.ieee.org/abstract/document/5288526/) using the *MEDfl* package. The primary objective of incorporating transfer learning with the package is to harness the capabilities of [Federated-Transfer learning](https://link.springer.com/chapter/10.1007/978-3-031-11748-0_3) in training models across different hospitals. In real-world scenarios, one of the clients or the aggregating server might possess a [pre-trained model](https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/#:~:text=A%20pretrained%20AI%20model%20is,8%2C%202022%20by%20Angie%20Lee). Leveraging this pre-trained model offers advantages such as enhancing performance and reducing training time.\n",
    "\n",
    "In some instances, a client may lack sufficient data to train a model entirely from scratch, hindering the ability to achieve optimal performance. Utilizing transfer learning becomes a viable strategy to maximize the benefits from each client, allowing the integration of previously learned knowledge to enhance model training and performance.\n",
    "\n",
    "<img src=\"../Images/FTL_comp.png\"  style=\"width:600px ;height:400px ; display:block ;margin:0 auto\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EiCu Data \n",
    "This tutorial involves the utilization of the eICU dataset, a CSV file contains information on 200,860 patients, to train a binary classifier model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Start\n",
    "\n",
    "To integrate Transfer Learning into the *MEDfl* package, several sequential steps are essential:\n",
    "\n",
    "1. **Importing a Pretrained Model:** Acquire or utilize a pretrained model containing learned knowledge from prior tasks or domains.\n",
    "2. **Initialization at the Central Server:** The central server initiates its model by copying the pretrained model's parameters or weights.\n",
    "3. **Initiating Federated Learning:** Upon initialization, the federated learning process begins, facilitating the exchange of model updates among participating clients for joint model training.\n",
    "\n",
    "### Importing a Pretrained Model:\n",
    "   - When importing a pretrained model, there are two options available:\n",
    "   \n",
    "     1. **Train and Save Locally:** Train a model localy, save it, and subsequently incorporate it for use.\n",
    "     2. **External Source or Previous Work:** Import a pretrained model from an external source or retrieve it from a previous project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train and Save Localy\n",
    "In this section, we aim to train a basic binary classifier model using the `eicu_sapsii_data.csv` dataset. Following the model training, we'll save the trained model for future utilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEDfl.LearningManager.utils import global_params\n",
    "\n",
    "import sys\n",
    "sys.path.append(global_params['base_url'])\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = global_params['base_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from MEDfl.LearningManager.model import Model\n",
    "from MEDfl.LearningManager.utils import global_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_hospital</th>\n",
       "      <th>site_region</th>\n",
       "      <th>age</th>\n",
       "      <th>pao2fio2</th>\n",
       "      <th>uo</th>\n",
       "      <th>admissiontype</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>chron_dis</th>\n",
       "      <th>gcs</th>\n",
       "      <th>hr</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sbp</th>\n",
       "      <th>sodium</th>\n",
       "      <th>tempc</th>\n",
       "      <th>wbc</th>\n",
       "      <th>event_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stay147985</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stay156248</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stay156308</td>\n",
       "      <td>site60</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stay157820</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay159036</td>\n",
       "      <td>site73</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id site_hospital site_region  age  pao2fio2  uo  admissiontype  \\\n",
       "0  stay147985        site73     Midwest   16       0.0   4              6   \n",
       "1  stay156248        site73     Midwest    7       0.0   0              6   \n",
       "2  stay156308        site60     Midwest   18       0.0   0              6   \n",
       "3  stay157820        site73     Midwest   12       0.0  11              6   \n",
       "4  stay159036        site73     Midwest   18       0.0   0              6   \n",
       "\n",
       "   bicarbonate  bilirubin  bun  chron_dis  gcs  hr  potassium  sbp  sodium  \\\n",
       "0            3          0    6          0    5   0          0    5       1   \n",
       "1            0          0    0          0    0   0          0    5       0   \n",
       "2            0          0    6          0    0   0          3    5       1   \n",
       "3            3          0   10          0    0   0          0    0       1   \n",
       "4            0          0    6          0    0   4          0    5       0   \n",
       "\n",
       "   tempc  wbc  event_death  \n",
       "0      0    0            1  \n",
       "1      0    0            0  \n",
       "2      0    0            0  \n",
       "3      0    0            0  \n",
       "4      0    3            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "data = pd.read_csv(global_params['base_url'] + '/notebooks/eicu_test.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing Steps\n",
    "\n",
    "Here, we perform several essential data preprocessing steps:\n",
    "\n",
    "1. **Drop Unnecessary Columns:** The code drops the 'subject_id' column and any other columns deemed unnecessary for the analysis. Additional columns can be added to the `columns_to_drop` list for removal.\n",
    "\n",
    "2. **Define Features and Target Variable:** The features are defined by selecting all columns except the 'deceased' column, which is designated as the target variable for the binary classification task.\n",
    "\n",
    "3. **Impute Missing Values:** Missing values in the selected features are imputed using the mean strategy. The `SimpleImputer` from the scikit-learn library is employed to fill missing values in the dataset.\n",
    "\n",
    "4. **Preview the Transformed Data:** The `.head()` function is used to display the first few rows of the transformed dataset after preprocessing.\n",
    "\n",
    "The code snippet provides a glimpse of the preprocessing steps, ensuring data cleanliness and preparation for training the binary classifier using the eICU dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_hospital</th>\n",
       "      <th>site_region</th>\n",
       "      <th>age</th>\n",
       "      <th>pao2fio2</th>\n",
       "      <th>uo</th>\n",
       "      <th>admissiontype</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>chron_dis</th>\n",
       "      <th>gcs</th>\n",
       "      <th>hr</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sbp</th>\n",
       "      <th>sodium</th>\n",
       "      <th>tempc</th>\n",
       "      <th>wbc</th>\n",
       "      <th>event_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_hospital  site_region   age  pao2fio2    uo  admissiontype  \\\n",
       "0           67.0          0.0  16.0       0.0   4.0            6.0   \n",
       "1           67.0          0.0   7.0       0.0   0.0            6.0   \n",
       "2           61.0          0.0  18.0       0.0   0.0            6.0   \n",
       "3           67.0          0.0  12.0       0.0  11.0            6.0   \n",
       "4           67.0          0.0  18.0       0.0   0.0            6.0   \n",
       "\n",
       "   bicarbonate  bilirubin   bun  chron_dis  gcs   hr  potassium  sbp  sodium  \\\n",
       "0          3.0        0.0   6.0        0.0  5.0  0.0        0.0  5.0     1.0   \n",
       "1          0.0        0.0   0.0        0.0  0.0  0.0        0.0  5.0     0.0   \n",
       "2          0.0        0.0   6.0        0.0  0.0  0.0        3.0  5.0     1.0   \n",
       "3          3.0        0.0  10.0        0.0  0.0  0.0        0.0  0.0     1.0   \n",
       "4          0.0        0.0   6.0        0.0  0.0  4.0        0.0  5.0     0.0   \n",
       "\n",
       "   tempc  wbc  event_death  \n",
       "0    0.0  0.0            1  \n",
       "1    0.0  0.0            0  \n",
       "2    0.0  0.0            0  \n",
       "3    0.0  0.0            0  \n",
       "4    0.0  3.0            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'subject_id' column and any other unnecessary columns\n",
    "columns_to_drop = [\"id\"]  # Add more columns to drop if needed\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "features = [col for col in data.columns if col != 'event_death']\n",
    "target = 'event_death'\n",
    "\n",
    "# Impute missing values using the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "encoder = LabelEncoder()\n",
    "data[\"site_hospital\"] = encoder.fit_transform(data[\"site_hospital\"])\n",
    "data[\"site_region\"] = encoder.fit_transform(data[\"site_region\"])\n",
    "\n",
    "data[features] = imputer.fit_transform(data[features])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modal initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Define the neural network model using PyTorch\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = BinaryClassifier(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare data loaders for PyTorch\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modal Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6682375013828278\n",
      "Epoch 2/20 - Loss: 0.626903623342514\n",
      "Epoch 3/20 - Loss: 0.5825505018234253\n",
      "Epoch 4/20 - Loss: 0.5580604672431946\n",
      "Epoch 5/20 - Loss: 0.5285914957523346\n",
      "Epoch 6/20 - Loss: 0.49749096035957335\n",
      "Epoch 7/20 - Loss: 0.48559616804122924\n",
      "Epoch 8/20 - Loss: 0.5011755645275116\n",
      "Epoch 9/20 - Loss: 0.47621373534202577\n",
      "Epoch 10/20 - Loss: 0.4585097342729568\n",
      "Epoch 11/20 - Loss: 0.48438641130924226\n",
      "Epoch 12/20 - Loss: 0.47160635590553285\n",
      "Epoch 13/20 - Loss: 0.4439723551273346\n",
      "Epoch 14/20 - Loss: 0.44068617224693296\n",
      "Epoch 15/20 - Loss: 0.4389739722013474\n",
      "Epoch 16/20 - Loss: 0.4385830879211426\n",
      "Epoch 17/20 - Loss: 0.4293429747223854\n",
      "Epoch 18/20 - Loss: 0.43730728328227997\n",
      "Epoch 19/20 - Loss: 0.42650032639503477\n",
      "Epoch 20/20 - Loss: 0.4289227932691574\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93        70\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.44      0.50      0.47        80\n",
      "weighted avg       0.77      0.88      0.82        80\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70  0]\n",
      " [10  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/USHERBROOKE/saho6810/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/local/USHERBROOKE/saho6810/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/local/USHERBROOKE/saho6810/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = (outputs.squeeze() > 0.5).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_tensor.numpy(), predictions.numpy()))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_tensor.numpy(), predictions.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Trained modal\n",
    "\n",
    "To save the trained model for future use in the Learning Manager as a pre-trained model to activate Transfer Learning, we use the `save_model` method available in the `Model` class within the *MEDfl* package. This method requires two parameters: the `model` to be saved and the `model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model \n",
    "Model.save_model(model=model , model_name='binary_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Pre-trained Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (fc1): Linear(in_features=17, out_features=64, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved Model \n",
    "model = Model.load_model(model_name='binary_classifier')\n",
    "\n",
    "# Ensure the model is in evaluation mode for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the Pretrained Model\n",
    "\n",
    "Following the initial training of the model, several modifications can be applied to adapt the pretrained model to the new context of the federated learning problem. Various options for modifying the pretrained model include:\n",
    "\n",
    "1. **Fine-Tuning Layers:** Selective updating of specific layers allows fine-tuning the model. Lower-level layers may retain learned representations, while higher-level layers adapt to the new task or domain.\n",
    "\n",
    "2. **Adjusting Learning Rates:** Modification of learning rates for different layers or layer groups aids in emphasizing specific layers' importance or controlling updates to pretrained layers.\n",
    "\n",
    "3. **Changing Activation Functions:** Experimentation with different activation functions in certain layers influences the model's learning behavior and adaptability to new data.\n",
    "\n",
    "4. **Transfer Learning Strategies:** Employing strategies like feature extraction or full retraining based on available data and computational resources to leverage pretrained model knowledge.\n",
    "\n",
    "5. **Customized Loss Functions:** Designing or utilizing domain-specific loss functions tailored to address specific requirements of the federated learning problem.\n",
    "\n",
    "These modification options provide flexibility and customization in adapting the pretrained model, ensuring its alignment with the unique demands and characteristics of the federated learning or transfer learning tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fine-Tuning Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, fine-tune the last layers of the pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "for param in model.output.parameters():\n",
    "    param.requires_grad = True  # Unfreeze output layer for fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Adjusting Learning Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different learning rates for different layer groups\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.fc1.parameters(), 'lr': 0.0001},  # Lower LR for certain layers\n",
    "    {'params': model.fc2.parameters(), 'lr': 0.0005},  # Higher LR for certain layers\n",
    "    {'params': model.output.parameters(), 'lr': 0.001}  # LR for output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Changing Activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different activation functions in certain layers\n",
    "# For instance, using LeakyReLU in place of ReLU\n",
    "model.fc1 = nn.Linear(input_dim, 64)\n",
    "model.fc2 = nn.Linear(64, 32)\n",
    "model.output = nn.Linear(32, 1)\n",
    "model.leaky_relu = nn.LeakyReLU()  # Introduce LeakyReLU activation function\n",
    "model.sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Updated Modal \n",
    "Model.save_model(model=model , model_name=\"updated_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (fc1): Linear(in_features=17, out_features=64, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the updated modal \n",
    "updated_model = Model.load_model(model_name=\"updated_model\")\n",
    "\n",
    "updated_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally\n",
    "After having the pretrained modal ready to use we have to pass it the Server class of the `MEDfl` package so the federated learing process can start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
