{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8813ef9e",
   "metadata": {},
   "source": [
    "# **NetManager**: Create a Federated Learning Network using MEDfl\n",
    "\n",
    "The `NetManager` module within `MEDfl` is responsible for the generation of federated learning networks. It relies on a CSV file containing a DataSet as input. Leveraging this Dataset file, the module creates various nodes within the network, assigns a dataset to each node, and generates the federated dataset for each node. Subsequently, these federated datasets are transferred to the subsequent package, `Learning Manager`.\n",
    "\n",
    "<img src='../Images/MEDfl_Diagramm.png' />\n",
    "\n",
    "The NetManager workflow involves five primary steps:\n",
    "\n",
    "1. **Network creation**\n",
    "2. **DataSets storage**\n",
    "3. **Nodes Creation**\n",
    "4. **FLsetup Creation**\n",
    "5. **Federated DataSet Creation**\n",
    "   \n",
    "<img src='../Images/NetManager_Diagramm.png' width=\"70%\" style=\"display : block ; margin :0 auto \" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82810c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEDfl.LearningManager.utils import global_params\n",
    "\n",
    "import sys\n",
    "sys.path.append(global_params['base_url'])\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = global_params['base_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64845a67",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cb2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "## MEDfl Imports \n",
    "from MEDfl.NetManager.node import Node\n",
    "from MEDfl.NetManager.network import Network\n",
    "from MEDfl.NetManager.dataset import DataSet\n",
    "from MEDfl.NetManager.flsetup import FLsetup\n",
    "\n",
    "# Utils\n",
    "from MEDfl.LearningManager.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1207b",
   "metadata": {},
   "source": [
    "### 0. DB Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43e09c",
   "metadata": {},
   "source": [
    "DB Creation: \n",
    "Check the `1_DB-checkpoint` tutorial to learn more about this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ee7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Creation \n",
    "!python3 ../../scripts/create_db.py\n",
    "\n",
    "# clearn DB \n",
    "# empty_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac06356",
   "metadata": {},
   "source": [
    "### 1. Network Creation\n",
    "\n",
    "<div style=\"display : flex\">\n",
    "<div style=\"width : 65%\">\n",
    "\n",
    "A. <u>**Automatically**</u> : \n",
    "      This method used when we don't have an idea about hospitals name, their datasets. so, the creation will based on some  variables on the datasets, for example in our Proof-Of-Concept with the *eICU* dataset, there are two variables that can be used, `site_hosiptal`, and `site_region`.  <br> Note that, hospitals can participate for <b>training</b> or for <b>testing</b> only. (this may be changed to support both modes) . <br> the set of hospitals or (Nodes) perform a network, and on MEDfl terminology, a network and its additional informations, refered as a <b>FLsetup (Federated Learning Setup)</b> <br>After the creation of an <b>FLsetup</b> it will be stored on the DB, by a unique ID, a name, a description, and a creation date.\n",
    "\n",
    "B. <u>**Manually**</u> :\n",
    "      Martin can also create a FLsetup manually, create a network, and add each node separately, then uploade a dataset on each node.\n",
    "   \n",
    "</div>\n",
    "\n",
    "<img width=\"270px\"  height=\"250px\" style=\"display:block ; margin : 0 auto\" src='../Images/NetworkCreation.png' />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b76d1",
   "metadata": {},
   "source": [
    "##### 1.1 Auto Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7693d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Auto_Net'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a nest work \"Net_1\"\n",
    "Net_1 = Network(name=\"Auto_Net\")\n",
    "Net_1.create_network()\n",
    "\n",
    "Net_1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f44e5",
   "metadata": {},
   "source": [
    "### 2. Data Storage\n",
    "<h4>MasterDataSet Creation</h4>\n",
    "\n",
    "Using the Methode `create_master_dataset` we will create a new table **MasterDataset**, and upload the data of `path_to_csv` to it, ( path_to_csv is optional and by default is the file specified on `MEDfl.LearningManager.params.yaml` : `path_to_master_csv`  )\n",
    "The MasterDataSet serves dual purposes within the network:\n",
    "\n",
    "1. **Auto-Creation of Nodes:**\n",
    "    - When automatically creating nodes, the MasterDataSet plays a pivotal role in dividing the data across various train and test nodes.\n",
    "\n",
    "2. **Manual Creation of Nodes:**\n",
    "    - In scenarios involving manual creation of nodes, the MasterDataSet acts as a reference point to verify compatibility between different dataSets and the MasterDataSet.\n",
    "  \n",
    "To Create MasterDataSet 3 main steps are executed: \n",
    "1. **Create a MasterDataSet Table on the DB** \n",
    "2. **Read The CSV DATA file**\n",
    "3. **Copy the Data from the CSV file to the DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7d61b",
   "metadata": {},
   "source": [
    "We Will use the CSV file `eicu_test.csv` as a MasterDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9acdb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    328\n",
      "1     71\n",
      "Name: event_death, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(global_params['base_url'] + '/notebooks/eicu_test.csv')\n",
    "\n",
    "# Calculate the counts of deceased individuals (0 or 1)\n",
    "deceased_counts = data['event_death'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(deceased_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04e6447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/local/USHERBROOKE/saho6810/MEDfl/code/MEDfl/notebooks/data/masterDataSet/Mimic_train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a MasterDataSet from Net_1\n",
    "Net_1.create_master_dataset()\n",
    "\n",
    "# Check if the Network has a masterDataSet Table ( 1: Table exists ; 0: Table doesn't exist)\n",
    "Net_1.mtable_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b92f2",
   "metadata": {},
   "source": [
    "### 3. Federeated Learning setup Creation (FlSetup creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6324351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLsetupId</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>NetId</th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flsetup_1</td>\n",
       "      <td>The first fl setup</td>\n",
       "      <td>2024-03-08 10:48:24</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLsetupId       name         description       creation_date  NetId  \\\n",
       "0          1  Flsetup_1  The first fl setup 2024-03-08 10:48:24      1   \n",
       "\n",
       "  column_name  \n",
       "0        None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auto FLsetup creation\n",
    "autoFl  = FLsetup(name = \"Flsetup_1\", description = \"The first fl setup\",network = Net_1)\n",
    "autoFl.create()\n",
    "\n",
    "# List all setups \n",
    "FLsetup.list_allsetups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1faa2b",
   "metadata": {},
   "source": [
    "### 4. Nodes Creation:\n",
    "Each node within the Network represents an FL Client on the Network and MEDfl packages provide two distinct approaches for node creation (**Auto Creation , Manually Creation**):\n",
    "\n",
    "1. **Auto Creation** :  In this method, nodes are generated automatically within the Network based on specified values from a particular column in the masterDataSet, as designated by the User. Following node creation, each node's DataSets are automatically assigned from the MasterDataSet.\n",
    "2. **Manually Creation**: In this method, nodes are manually created, and DataSets are separately and manually assigned to each individual node\n",
    "\n",
    "\n",
    "Let's start with the auto creation and see How the process goes : \n",
    "\n",
    "The user should create a parameters dictionary that contains  :\n",
    "<ul> \n",
    "    <li>The name of the column that be used to create the nodes, which is the main element in the <b>Automatic Method</b></li> \n",
    "    <li> The lists of the train/test nodes</li>\n",
    "    </ul> \n",
    "and parse it to the create_nodes_from_master_dataset function from the FLsetup class.<br>\n",
    "Node is also an object, and it will be stored on the DataBase.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c74d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Midwest', 'South', 'West', 'Northeast']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {'column_name' : 'site_region','train_nodes' : [\"Midwest\",\"South\"] , 'test_nodes' : ['West','Northeast'] }\n",
    "\n",
    "eicu_nodes = autoFl.create_nodes_from_master_dataset(params_dict = params_dict )\n",
    "\n",
    "[node.name  for node in eicu_nodes]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6731b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLsetupId</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>NetId</th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flsetup_1</td>\n",
       "      <td>The first fl setup</td>\n",
       "      <td>2024-02-13 14:57:37</td>\n",
       "      <td>1</td>\n",
       "      <td>site_region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLsetupId       name         description       creation_date  NetId  \\\n",
       "0          1  Flsetup_1  The first fl setup 2024-02-13 14:57:37      1   \n",
       "\n",
       "   column_name  \n",
       "0  site_region  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all setups \n",
    "FLsetup.list_allsetups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f722948",
   "metadata": {},
   "source": [
    "### 5. Creating a Federated Dataset\n",
    "\n",
    "In this phase, we will divide the data from each node into the following segments:\n",
    "\n",
    "<div style=\"display : flex\">\n",
    "<div style=\"width : 50%\">\n",
    "\n",
    "1. **Train Loader:** This segment is utilized for training purposes at each node.\n",
    "2. **Validation Loader:** Used for validation during the training phase.\n",
    "3. **Test Loaders:** Utilized to test the model within the test nodes.\n",
    "4. **Holdout Data:** This dataset is reserved for the final testing of the model after the Federated Learning (FL) process.\n",
    "   \n",
    "</div>\n",
    "\n",
    "<img width=\"30%\" style=\"display:block ; margin : 0 auto\" src='../Images/FlDatasetDiagramm.png' />\n",
    "</div>\n",
    "\n",
    "\n",
    "To generate an FL DataSet, the method `create_federated_dataset` is employed, which requires several arguments:\n",
    "\n",
    "1. `output`: The required argument indicating the output feature of our dataset.\n",
    "2. `fit_encode`: An array of features to be encoded (typically string type features encoded to integers). By default, it's an empty array.\n",
    "3. `to_drop`: An array of features to be removed from the dataset. By default, it's an empty array.\n",
    "4. `fill_strategy`: A strategy for handling missing values in the dataset. Default set to 'mean'.\n",
    "5. `test_frac`: The fraction of the dataset allocated for testing. Default set to 0.2.\n",
    "6. `val_frac`: The fraction of the dataset allocated for validation. Default set to 0.1.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "883f33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Federated DataSet for the autoFL\n",
    "fl_dataset = autoFl.create_federated_dataset(\n",
    "    output=\"event_death\", \n",
    "    fit_encode=[\"site_hospital\", \"site_region\"], \n",
    "    to_drop=[ \"event_death\" , \"id\"], \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c645e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FedId</th>\n",
       "      <th>FLsetupId</th>\n",
       "      <th>FLpipeId</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Flsetup_1_Feddataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FedId  FLsetupId FLpipeId                  name\n",
       "0      1          1     None  Flsetup_1_Feddataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Federated DataSet of the auto FL \n",
    "data = autoFl.get_flDataSet()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a9069",
   "metadata": {},
   "source": [
    "### 1.2 Manualy Creation of a Network\n",
    "\n",
    "The manual setup of FLsetup using MEDfl differs slightly from the automated method but operates within the same scope. The main distinction lies in creating all objects (FLsetup, network, training nodes, and test nodes) manually.\n",
    "\n",
    "To accomplish this, we will undertake the following steps:\n",
    "\n",
    "- Construct a network.\n",
    "- Generate a Master Dataset, utilizing the master_dataset table to ensure uniform dataset formats across all nodes (following horizontal federated learning principles).\n",
    "- Establish training and testing nodes within the network.\n",
    "- Upload datasets to each respective node.\n",
    "- Create the FLsetup object to streamline organization and simplify the storage process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d175bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man_network'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate the network object\n",
    "network_man = Network(name=\"man_network\")\n",
    "# Create the network and store it \n",
    "network_man.create_network()\n",
    "\n",
    "network_man.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac8f133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetId</th>\n",
       "      <th>NetName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Auto_Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>man_network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NetId      NetName\n",
       "0      1     Auto_Net\n",
       "1      2  man_network"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all networks on the DB \n",
    "Network.list_allnetworks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4938330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/local/USHERBROOKE/saho6810/MEDfl/code/MEDfl/notebooks/data/masterDataSet/Mimic_train.csv\n"
     ]
    }
   ],
   "source": [
    "network_man.create_master_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c788255",
   "metadata": {},
   "source": [
    "2. Nodes Creations\n",
    "\n",
    "In order to manually create a node, it's necessary to define both the name and the node's type. If `train = 1` , it indicates a train node; otherwise, it signifies a test node `train = 0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b4f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 nodes \n",
    "hospital_1,hospital_2,hospital_3 = Node(name = \"hospital_1\", train = 1),Node(name = \"hospital_2\", train = 1),Node(name = \"hospital_3\", train = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dceb486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 3 nodes to the man_network \n",
    "network_man.add_node(hospital_1)\n",
    "network_man.add_node(hospital_2)\n",
    "network_man.add_node(hospital_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6eb8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeId</th>\n",
       "      <th>NodeName</th>\n",
       "      <th>train</th>\n",
       "      <th>NetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hospital_1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hospital_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>hospital_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NodeId    NodeName  train  NetId\n",
       "0       1  hospital_1      1      2\n",
       "1       2  hospital_2      1      2\n",
       "2       3  hospital_3      0      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all created nodes on the db \n",
    "Node.list_allnodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2ccdb",
   "metadata": {},
   "source": [
    "### 3. Upload DataSets To nodes \n",
    "\n",
    "For uploading a dataSet to a node, it's essential to provide a name for the dataset and the file path of the CSV file containing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f8f899",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(mysql.connector.errors.ProgrammingError) 1054 (42S22): Unknown column 'id' in 'field list'\n[SQL: INSERT INTO DataSets(DataSetName,nodeId,id,site_hospital,site_region,age,pao2fio2,uo,admissiontype,bicarbonate,bilirubin,bun,chron_dis,gcs,hr,potassium,sbp,sodium,tempc,wbc,event_death) VALUES ('hospital_1_dataset',1, 'stay147985','site73','Midwest',16,0.0,4,6,3,0,6,0,5,0,0,5,1,0,0,1)]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/connection_cext.py:661\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    660\u001b[0m         query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Unknown column 'id' in 'field list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1910\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1910\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/cursor_cext.py:374\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/opentelemetry/context_propagation.py:83\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/connection_cext.py:669\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    670\u001b[0m         err\u001b[38;5;241m.\u001b[39merrno, msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    671\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 1054 (42S22): Unknown column 'id' in 'field list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m Ds_3 \u001b[38;5;241m=\u001b[39m global_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_url\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/eicu_test_3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pload the DataSets \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mhospital_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhospital_1_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDs_1\u001b[49m\u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m hospital_2\u001b[38;5;241m.\u001b[39mupload_dataset( dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhospital_2_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m , path_to_csv\u001b[38;5;241m=\u001b[39mDs_2)\n\u001b[1;32m      9\u001b[0m hospital_3\u001b[38;5;241m.\u001b[39mupload_dataset( dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhospital_3_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m , path_to_csv\u001b[38;5;241m=\u001b[39mDs_3 )\n",
      "File \u001b[0;32m~/MEDfl/code/MEDfl/MEDfl/NetManager/node.py:135\u001b[0m, in \u001b[0;36mNode.upload_dataset\u001b[0;34m(self, dataset_name, path_to_csv)\u001b[0m\n\u001b[1;32m    131\u001b[0m query_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m VALUES (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnodeId\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_str(data_df,\u001b[38;5;250m \u001b[39mrow,\u001b[38;5;250m \u001b[39mx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m query \u001b[38;5;241m=\u001b[39m query_1[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m query_2[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1385\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   1382\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m   1383\u001b[0m     )\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py:334\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1577\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1565\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1567\u001b[0m )\n\u001b[1;32m   1569\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1570\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1571\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1576\u001b[0m )\n\u001b[0;32m-> 1577\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1591\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1592\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         ret,\n\u001b[1;32m   1597\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1953\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1950\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1953\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:2134\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2132\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   2133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2134\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2138\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py:211\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    208\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1910\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1908\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1910\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1915\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1916\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1917\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1922\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/cursor_cext.py:374\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all parameters were used in the SQL statement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    382\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    383\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/opentelemetry/context_propagation.py:83\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mquery_attrs_append(value\u001b[38;5;241m=\u001b[39m(TRACEPARENT_HEADER_NAME, tp_header))\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tp_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mysql/connector/connection_cext.py:669\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m    662\u001b[0m         query,\n\u001b[1;32m    663\u001b[0m         raw\u001b[38;5;241m=\u001b[39mraw,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m         query_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_attrs,\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    670\u001b[0m         err\u001b[38;5;241m.\u001b[39merrno, msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    671\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    673\u001b[0m     addr \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    675\u001b[0m     )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (mysql.connector.errors.ProgrammingError) 1054 (42S22): Unknown column 'id' in 'field list'\n[SQL: INSERT INTO DataSets(DataSetName,nodeId,id,site_hospital,site_region,age,pao2fio2,uo,admissiontype,bicarbonate,bilirubin,bun,chron_dis,gcs,hr,potassium,sbp,sodium,tempc,wbc,event_death) VALUES ('hospital_1_dataset',1, 'stay147985','site73','Midwest',16,0.0,4,6,3,0,6,0,5,0,0,5,1,0,0,1)]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "# Define the path of the files \n",
    "Ds_1 = global_params['base_url']+ '/notebooks/eicu_test_1.csv'\n",
    "Ds_2 = global_params['base_url']+ '/notebooks/eicu_test_2.csv'\n",
    "Ds_3 = global_params['base_url']+ '/notebooks/eicu_test_3.csv'\n",
    "\n",
    "# pload the DataSets \n",
    "hospital_1.upload_dataset( dataset_name = \"hospital_1_dataset\" , path_to_csv=Ds_1  )\n",
    "hospital_2.upload_dataset( dataset_name = \"hospital_2_dataset\" , path_to_csv=Ds_2)\n",
    "hospital_3.upload_dataset( dataset_name = \"hospital_3_dataset\" , path_to_csv=Ds_3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efe5af",
   "metadata": {},
   "source": [
    "### 4. Create the FLsetup \n",
    "\n",
    "Now, let's create the Federated Learning setup of the manual network `man_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76e7a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FLsetup for man_network \n",
    "fl_setup = FLsetup(name = \"Manual_Flsetup\", description = \"The first manual fl setup\",network = network_man)\n",
    "fl_setup.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd18c5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLsetupId</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>NetId</th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flsetup_1</td>\n",
       "      <td>The first fl setup</td>\n",
       "      <td>2024-02-13 14:57:37</td>\n",
       "      <td>1</td>\n",
       "      <td>site_region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Manual_Flsetup</td>\n",
       "      <td>The first manual fl setup</td>\n",
       "      <td>2024-02-13 15:08:34</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLsetupId            name                description       creation_date  \\\n",
       "0          1       Flsetup_1         The first fl setup 2024-02-13 14:57:37   \n",
       "1          2  Manual_Flsetup  The first manual fl setup 2024-02-13 15:08:34   \n",
       "\n",
       "   NetId  column_name  \n",
       "0      1  site_region  \n",
       "1      2         None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all created Setups \n",
    "FLsetup.list_allsetups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31042cd2",
   "metadata": {},
   "source": [
    "### 5. Create the Federated DataSet\n",
    "\n",
    "finaly, we will create the federated DataSet the `man_network` and pass it to the `Learning manager` package\n",
    "\n",
    "**when creating a fl Dataset for a manual network you need always to drop these two comumns `DataSetName` and `NodeId`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87dceacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FLDataSet\n",
    "fl_dataset = fl_setup.create_federated_dataset(\n",
    "    output=\"event_death\", \n",
    "    fit_encode=[\"site_hospital\", \"site_region\"], \n",
    "    to_drop=[ \"event_death\" , \"id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "596b5db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the fl_dataSet\n",
    "fl_dataset.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92674428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FedId</th>\n",
       "      <th>FLsetupId</th>\n",
       "      <th>FLpipeId</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>Manual_Flsetup_Feddataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FedId  FLsetupId FLpipeId                       name\n",
       "0      2          2     None  Manual_Flsetup_Feddataset"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Federated DataSet of the manual FL \n",
    "data = fl_setup.get_flDataSet()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86641506",
   "metadata": {},
   "source": [
    "# THE END \n",
    "\n",
    "<img src='../Images/netMan.png' width=\"50%\"  />\n",
    "\n",
    "By now we completed the workflow of the first sub package of `MEDfl` whiwh is the `Learning Manager` subpackage, we started with a csv file of data and have successfully generated our federated dataset.\n",
    "\n",
    "Throughout this process, we employed two distinct methods to create the FedDataset: automated creation and manual creation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
